{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Demo\n",
    "\n",
    "## First we'll do Geopy which is not NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(35.6869996, -105.9377997)\n{'place_id': 235279350, 'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright', 'osm_type': 'relation', 'osm_id': 171264, 'boundingbox': ['35.5880434', '35.7546236', '-106.1121583', '-105.8941768'], 'lat': '35.6869996', 'lon': '-105.9377997', 'display_name': 'Santa Fe, Santa Fe County, New Mexico, United States of America', 'class': 'boundary', 'type': 'administrative', 'importance': 0.7652548712385518, 'icon': 'https://nominatim.openstreetmap.org/images/mapicons/poi_boundary_administrative.p.20.png'}\n"
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='Justin_Demo_App')\n",
    "\n",
    "location = geolocator.geocode('Santa Fe, NM')\n",
    "\n",
    "print((location.latitude, location.longitude))\n",
    "\n",
    "print(location.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sia\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   neg    neu    pos  compound  \\\n0  0.0  0.641  0.359    0.4215   \n1  0.0  0.833  0.167    0.4215   \n2  0.0  0.682  0.318    0.4215   \n3  0.0  0.682  0.318    0.4215   \n4  0.0  0.328  0.672    0.6249   \n\n                                             comment  \n0             I liked making slime and bouncy balls   \n1  I liked the bounce, splat, and stretch because...  \n2   I liked that we worked with different materials   \n3             I liked when we made the bouncy balls   \n4                                    It was awesome   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.641</td>\n      <td>0.359</td>\n      <td>0.4215</td>\n      <td>I liked making slime and bouncy balls</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.833</td>\n      <td>0.167</td>\n      <td>0.4215</td>\n      <td>I liked the bounce, splat, and stretch because...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.682</td>\n      <td>0.318</td>\n      <td>0.4215</td>\n      <td>I liked that we worked with different materials</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.682</td>\n      <td>0.318</td>\n      <td>0.4215</td>\n      <td>I liked when we made the bouncy balls</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.328</td>\n      <td>0.672</td>\n      <td>0.6249</td>\n      <td>It was awesome</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "analyzer = sia()\n",
    "results = []\n",
    "\n",
    "df = pd.read_excel('eyh2020.xlsx', skiprows=7, index_col=0, usecols=[0,6], sheet_name=2)\n",
    "df.columns = ['comments']\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    score = analyzer.polarity_scores(row['comments'])\n",
    "    score['comment'] = row['comments']\n",
    "    results.append(score)\n",
    "\n",
    "res_df = pd.DataFrame.from_records(results)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['This',\n 'is',\n 'an',\n 'example',\n 'sentence',\n 'However',\n 'it',\n 'isn',\n 't',\n 'a',\n 'very',\n 'informative',\n 'one']"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# tokenization example\n",
    "example = \"This is an example sentence! However, it isn't a very informative one~\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(lines):\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        tok = tokenizer.tokenize(line)\n",
    "        tok = [t.lower() for t in tok if t.lower() not in stop_words]\n",
    "        tokens.extend(tok)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('liked', 69),\n ('fun', 30),\n ('like', 28),\n ('really', 14),\n ('make', 13),\n ('got', 11),\n ('different', 11),\n ('loved', 11),\n ('everything', 10),\n ('workshop', 9),\n ('slime', 8),\n ('awesome', 8),\n ('would', 8),\n ('hands', 7),\n ('think', 7),\n ('making', 6),\n ('cool', 6),\n ('lot', 5),\n ('hard', 5),\n ('things', 5)]"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "pc = list(res_df[res_df.compound >= 0.25].comment)\n",
    "\n",
    "pt = normalize(pc)\n",
    "pf = FreqDist(pt)\n",
    "\n",
    "pf.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595279017886",
   "display_name": "Python 3.7.7 64-bit ('anaconda3-2020.02': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}